{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d16aa89-c1a2-4bb6-aaee-3959e43daf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load the data set\n",
    "df = pandas.read_csv(\"data//ml_house_data_set.csv\")\n",
    "\n",
    "# Remove the fields from the data set that we don't want to include in our model\n",
    "del df['house_number']\n",
    "del df['unit_number']\n",
    "del df['street_name']\n",
    "del df['zip_code']\n",
    "\n",
    "# Replace categorical data with one-hot encoded data\n",
    "features_df = pandas.get_dummies(df, columns=['garage_type', 'city'])\n",
    "del features_df['sale_price']\n",
    "\n",
    "X = features_df.values\n",
    "y = df['sale_price'].values\n",
    "\n",
    "# Split the data set in a training set (70%) and a test set (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Create the model\n",
    "model = ensemble.GradientBoostingRegressor()\n",
    "\n",
    "# Parameters we want to try\n",
    "param_grid = {\n",
    "    'n_estimators': [500, 1000, 3000],\n",
    "    'max_depth': [4, 6],\n",
    "    'min_samples_leaf': [3, 5, 9, 17],\n",
    "    'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "    'max_features': [1.0, 0.3, 0.1],\n",
    "    'loss': ['ls', 'lad', 'huber']\n",
    "}\n",
    "\n",
    "# Define the grid search we want to run. Run it with four cpus in parallel.\n",
    "gs_cv = GridSearchCV(model, param_grid, n_jobs=-1, verbose=100)\n",
    "\n",
    "# Run the grid search - on only the training data!\n",
    "gs_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the parameters that gave us the best result!\n",
    "print(gs_cv.best_params_)\n",
    "\n",
    "# After running a .....long..... time, the output will be something like\n",
    "# {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_leaf': 9, 'n_estimators': 3000, 'max_features': 0.1, 'max_depth': 6}\n",
    "\n",
    "# That is the combination that worked best.\n",
    "\n",
    "# Find the error rate on the training set using the best parameters\n",
    "mse = mean_absolute_error(y_train, gs_cv.predict(X_train))\n",
    "print(\"Training Set Mean Absolute Error: %.4f\" % mse)\n",
    "\n",
    "# Find the error rate on the test set using the best parameters\n",
    "mse = mean_absolute_error(y_test, gs_cv.predict(X_test))\n",
    "print(\"Test Set Mean Absolute Error: %.4f\" % mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2937b5-bf1a-4716-9cf3-c244d8850827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "95dec33e47c85f12e0e716dc7e67c6036277a1191db17df37e1676f331928323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
